7


----------------------------------------------------------------------------
Training ModelTree with config/adult.yml in env gbdt

Namespace(config='config/adult.yml', model_name='ModelTree', dataset='Adult', objective='binary', use_gpu=False, gpu_ids=[0, 1], data_parallel=True, optimize_hyperparameters=False, n_trials=2, direction='maximize', num_splits=5, shuffle=True, seed=221, scale=True, target_encode=True, one_hot_encode=False, batch_size=128, val_batch_size=256, early_stopping_rounds=20, epochs=3, logging_period=100, num_features=14, num_classes=1, cat_idx=[1, 3, 5, 6, 7, 8, 9, 13], cat_dims=[9, 16, 7, 15, 6, 5, 2, 42])
Train model with given hyperparameters
Loading dataset Adult...
Dataset loaded!
(32561, 14)
Scaling the data...
{'Log Loss - mean': 0.32339590523728035, 'Log Loss - std': 0.0, 'AUC - mean': 0.9025939470443731, 'AUC - std': 0.0, 'Accuracy - mean': 0.8440042990941194, 'Accuracy - std': 0.0, 'F1 score - mean': 0.8440042990941194, 'F1 score - std': 0.0}
{'Log Loss - mean': 0.3162831356800754, 'Log Loss - std': 0.007112769557204968, 'AUC - mean': 0.9065625938783387, 'AUC - std': 0.003968646833965583, 'Accuracy - mean': 0.8488295451244553, 'Accuracy - std': 0.00482524603033585, 'F1 score - mean': 0.8488295451244553, 'F1 score - std': 0.00482524603033585}
{'Log Loss - mean': 0.31267662081074293, 'Log Loss - std': 0.007729266428411354, 'AUC - mean': 0.9090025795510832, 'AUC - std': 0.004733620738387608, 'Accuracy - mean': 0.85233189986184, 'Accuracy - std': 0.00632890013471087, 'F1 score - mean': 0.85233189986184, 'F1 score - std': 0.00632890013471087}
{'Log Loss - mean': 0.31295973644638797, 'Log Loss - std': 0.006711678853346993, 'AUC - mean': 0.9085514643963222, 'AUC - std': 0.0041732347908709005, 'Accuracy - mean': 0.8527777946752497, 'Accuracy - std': 0.0055351331727642025, 'F1 score - mean': 0.8527777946752497, 'F1 score - std': 0.0055351331727642025}
{'Log Loss - mean': 0.31451029633424166, 'Log Loss - std': 0.0067567928995682204, 'AUC - mean': 0.9073735680314888, 'AUC - std': 0.004413895137057416, 'Accuracy - mean': 0.8518168303347944, 'Accuracy - std': 0.005310740931988201, 'F1 score - mean': 0.8518168303347944, 'F1 score - std': 0.005310740931988201}
Results: {'Log Loss - mean': 0.31451029633424166, 'Log Loss - std': 0.0067567928995682204, 'AUC - mean': 0.9073735680314888, 'AUC - std': 0.004413895137057416, 'Accuracy - mean': 0.8518168303347944, 'Accuracy - std': 0.005310740931988201, 'F1 score - mean': 0.8518168303347944, 'F1 score - std': 0.005310740931988201}
Train time: 0.03620457240000006
Inference time: 0.03267034960000008
Finished cross validation
{'Log Loss - mean': 0.31451029633424166, 'Log Loss - std': 0.0067567928995682204, 'AUC - mean': 0.9073735680314888, 'AUC - std': 0.004413895137057416, 'Accuracy - mean': 0.8518168303347944, 'Accuracy - std': 0.005310740931988201, 'F1 score - mean': 0.8518168303347944, 'F1 score - std': 0.005310740931988201}
(0.03620457240000006, 0.03267034960000008)


----------------------------------------------------------------------------
Training ModelTree with config/california_housing.yml in env gbdt

Namespace(config='config/california_housing.yml', model_name='ModelTree', dataset='CaliforniaHousing', objective='regression', use_gpu=True, gpu_ids=[0, 1], data_parallel=True, optimize_hyperparameters=False, n_trials=2, direction='minimize', num_splits=5, shuffle=True, seed=221, scale=True, target_encode=False, one_hot_encode=False, batch_size=128, val_batch_size=256, early_stopping_rounds=20, epochs=3, logging_period=100, num_features=8, num_classes=1, cat_idx=None, cat_dims=None)
Train model with given hyperparameters
Loading dataset CaliforniaHousing...
Dataset loaded!
(20640, 8)
Scaling the data...
{'MSE - mean': 0.33518779830633605, 'MSE - std': 0.0, 'R2 - mean': 0.7528651550897398, 'R2 - std': 0.0}
{'MSE - mean': 0.33593134300870553, 'MSE - std': 0.0007435447023695085, 'R2 - mean': 0.7458195703567738, 'R2 - std': 0.007045584732966015}
{'MSE - mean': 0.5400539427683589, 'MSE - std': 0.2886735873573512, 'R2 - mean': 0.5903191418559708, 'R2 - std': 0.21998604509684924}
{'MSE - mean': 0.5178426516329945, 'MSE - std': 0.2529414050526751, 'R2 - mean': 0.6117082738494104, 'R2 - std': 0.1940821473766021}
{'MSE - mean': 0.48115668844972426, 'MSE - std': 0.23783801859827677, 'R2 - mean': 0.6380251364365048, 'R2 - std': 0.1813962870897928}
Results: {'MSE - mean': 0.48115668844972426, 'MSE - std': 0.23783801859827677, 'R2 - mean': 0.6380251364365048, 'R2 - std': 0.1813962870897928}
Train time: 0.0188405618
Inference time: 0.01057575719999999
Finished cross validation
{'MSE - mean': 0.48115668844972426, 'MSE - std': 0.23783801859827677, 'R2 - mean': 0.6380251364365048, 'R2 - std': 0.1813962870897928}
(0.0188405618, 0.01057575719999999)


----------------------------------------------------------------------------
Training ModelTree with config/covertype.yml in env gbdt

Namespace(config='config/covertype.yml', model_name='ModelTree', dataset='Covertype', objective='classification', use_gpu=False, gpu_ids=[0, 1], data_parallel=True, optimize_hyperparameters=False, n_trials=2, direction='minimize', num_splits=5, shuffle=True, seed=221, scale=True, target_encode=True, one_hot_encode=False, batch_size=128, val_batch_size=256, early_stopping_rounds=20, epochs=3, logging_period=100, num_features=54, num_classes=7, cat_idx=None, cat_dims=None)
Train model with given hyperparameters
Loading dataset Covertype...
Dataset loaded!
(581012, 54)
Having 7 classes as target.
Scaling the data...
ModelTree is not implemented for multi-class classification yet
